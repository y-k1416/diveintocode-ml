{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c91pWEhwVRKs"
   },
   "source": [
    "# Sprint19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1585123686768,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "917rkJIru9K_",
    "outputId": "de942408-1a63-41b2-89f3-256112f58ae8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SUwj4POVwhQ"
   },
   "source": [
    "# 【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcKN5FScVzWs"
   },
   "source": [
    "# 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68X2aQI8bExI"
   },
   "source": [
    "# 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q-pPPtUVmKP"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:08:26.011539Z",
     "start_time": "2019-09-25T07:08:20.644512Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J8Ve5ciaVmKT"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5n6cotFgV7Hl"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1585117554355,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "2M-hdkdKXHLx",
    "outputId": "376a0703-9244-43aa-ae6a-d8cd53cc26d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# 自分のマイドライブにマウントする\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1585102999979,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "xP1TGhwGX37V",
    "outputId": "a07cb5b1-19e8-48e8-883c-a562843a8ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnP2WWYXVmKa"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-k3_kSVVmKh"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbqMujplVmKl"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2504,
     "status": "ok",
     "timestamp": 1585103013073,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "GlvkSSnBVmKm",
    "outputId": "5b364930-0d49-4b4f-e589-f85db231629e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n",
      "1  3cb59a4fdc                                             1 5656\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n",
      "3  c78c89577c                                              101 1\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  3e06571ef3      1 1\n",
      "1  a51b08d882      1 1\n",
      "2  c32590b06f      1 1\n",
      "3  15f7a047c7      1 1\n",
      "4  e8827bc832      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312\n",
      "1  3cb59a4fdc                                             1 5656  603\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687\n",
      "3  c78c89577c                                              101 1  236\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./unet/data/salt/train.csv')\n",
    "test = pd.read_csv('./unet/data/salt/sample_submission.csv')\n",
    "depth = pd.read_csv('./unet/data/salt/depths.csv')\n",
    "\n",
    "train_src = './unet/data/salt/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dp8lcwWFVmKu"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23842,
     "status": "ok",
     "timestamp": 1585110620383,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "lfVkFJbvVmKw",
    "outputId": "5d3612cd-7bf1-41bc-cf0c-b4bab1615ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./unet/data/salt/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./unet/data/salt/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14662,
     "status": "ok",
     "timestamp": 1585110620385,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "8MuGMVnTVmK1",
    "outputId": "fa3548d4-c3ae-47fc-f8a6-f850998c3939",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7d0a2a8e48>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFSCAYAAAAJl+KKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIz+NAsIiIiIjKDD80iIiIiIjP8/8TTB8d9jzqbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKn9y-vjVmK7"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AU8WJ8ooVmK8"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lG5QOsZKVmLA"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25201,
     "status": "ok",
     "timestamp": 1585110636254,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "E-8U7dbBVmLC",
    "outputId": "7e1ca8fe-79f7-420e-d555-58700c9e271e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epEHnZ4BVmLH"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biOp6V3sVmLJ"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iU1g6MqyVmLO"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:09:31.695684Z",
     "start_time": "2019-09-25T07:09:24.147636Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8688,
     "status": "ok",
     "timestamp": 1585117579245,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "1x0UbdJLVmLP",
    "outputId": "b5e7e2df-3103-4634-f7f1-dff7181a2594",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 512)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 512)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 512)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 28, 512)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 1024) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 1024) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 1024) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 1024) 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 1024) 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 1024) 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 2048)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 2048)   0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 2048)   0           add_22[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2E4PepgWJNR"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8902,
     "status": "ok",
     "timestamp": 1585117907748,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "9OYpFxjQWJJz",
    "outputId": "95b184e5-dbfc-4158-8cab-59fa3da6071b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425429,
     "status": "ok",
     "timestamp": 1585118341678,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "hVnE6_OCWI8G",
    "outputId": "1999023e-62bf-4857-d534-b459fbaed1f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "3200/3200 [==============================] - 83s 26ms/step - loss: 0.8581 - my_iou_metric: 0.2825 - val_loss: 0.8557 - val_my_iou_metric: 0.4003\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.40025, saving model to unet_resnet.h5\n",
      "Epoch 2/5\n",
      "3200/3200 [==============================] - 63s 20ms/step - loss: 0.6343 - my_iou_metric: 0.4323 - val_loss: 0.6275 - val_my_iou_metric: 0.3650\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.40025\n",
      "Epoch 3/5\n",
      "3200/3200 [==============================] - 62s 19ms/step - loss: 0.5616 - my_iou_metric: 0.4880 - val_loss: 0.5434 - val_my_iou_metric: 0.5443\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.40025 to 0.54425, saving model to unet_resnet.h5\n",
      "Epoch 4/5\n",
      "3200/3200 [==============================] - 62s 19ms/step - loss: 0.5334 - my_iou_metric: 0.5177 - val_loss: 1.2489 - val_my_iou_metric: 0.3152\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.54425\n",
      "Epoch 5/5\n",
      "3200/3200 [==============================] - 62s 19ms/step - loss: 0.4948 - my_iou_metric: 0.5438 - val_loss: 2.0082 - val_my_iou_metric: 0.3519\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.54425\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 5  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2t-VjzjXHZx"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wkk8BzaTXQyT"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37745,
     "status": "ok",
     "timestamp": 1585118419760,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "vfJfMGqnXSK7",
    "outputId": "f28a830b-de0b-4e6b-b37c-03aff82e705f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:37<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1585118431473,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "lw-3N5CLXSHq",
    "outputId": "72c78a63-9249-48df-c41f-55c624f11de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3819 at threshold: 0.800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.372254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.008169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.369250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.375125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.378062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.381875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.372254\n",
       "std     0.204939   0.008169\n",
       "min     0.200000   0.354500\n",
       "25%     0.370000   0.369250\n",
       "50%     0.540000   0.375125\n",
       "75%     0.710000   0.378062\n",
       "max     0.880000   0.381875"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1585118436562,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "0y5oyqW-XZWL",
    "outputId": "fb86a02f-0aec-4783-bdf4-b0abb30da7a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7a75314a20>"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIWCAYAAACoQ2BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQhj5OeMTQBH"
   },
   "source": [
    "# VGG16のモデルを転移学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34183,
     "status": "ok",
     "timestamp": 1585110657551,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "ADS-QHWlflfv",
    "outputId": "eca45606-b08a-4e67-c943-8aec14dea4fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "OHEiSbAJVmLU"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PpMmRmpcVmLV"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_DjdGgIVmLW"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAcEdgLkVmLd"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y45-FOThVmLe"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block2_conv1').output\n",
    "    encoder2 = base_model.get_layer('block3_conv1').output\n",
    "    encoder3 = base_model.get_layer('block4_conv1').output\n",
    "    encoder4 = base_model.get_layer('block5_conv1').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67E1RR2xVmLk"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1585131459549,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "fcFmyTdbVmLm",
    "outputId": "cff0b54b-b29b-4ae6-efa5-d4a2fc6d7657",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,850,817\n",
      "Trainable params: 22,848,705\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwIVTtxcVmLy"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 343586,
     "status": "ok",
     "timestamp": 1585131807921,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "WdFNwjRmVmLz",
    "outputId": "c2a3e80c-177b-4833-8bc7-ed6762f192f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,917,105\n",
      "Trainable params: 28,911,825\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "3200/3200 [==============================] - 71s 22ms/step - loss: 0.9007 - my_iou_metric: 0.1474 - val_loss: 2.7324 - val_my_iou_metric: 0.1601\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.16013, saving model to unet_vgg16.h5\n",
      "Epoch 2/5\n",
      "3200/3200 [==============================] - 61s 19ms/step - loss: 0.6930 - my_iou_metric: 0.2283 - val_loss: 0.9536 - val_my_iou_metric: 0.2981\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.16013 to 0.29812, saving model to unet_vgg16.h5\n",
      "Epoch 3/5\n",
      "3200/3200 [==============================] - 61s 19ms/step - loss: 0.6369 - my_iou_metric: 0.2943 - val_loss: 0.9074 - val_my_iou_metric: 0.2770\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.29812\n",
      "Epoch 4/5\n",
      "3200/3200 [==============================] - 61s 19ms/step - loss: 0.6177 - my_iou_metric: 0.3381 - val_loss: 0.6572 - val_my_iou_metric: 0.3968\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.29812 to 0.39675, saving model to unet_vgg16.h5\n",
      "Epoch 5/5\n",
      "3200/3200 [==============================] - 61s 19ms/step - loss: 0.5858 - my_iou_metric: 0.3738 - val_loss: 0.5089 - val_my_iou_metric: 0.5425\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.39675 to 0.54250, saving model to unet_vgg16.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 5  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_eZvRNAVmL3"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLTHN-8mVmL4"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6zMWJ52VmL_"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GahRGpMCVmMA"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39819,
     "status": "ok",
     "timestamp": 1585114359849,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "EgOar3OqVmME",
    "outputId": "8823f6a0-13a4-4039-e41e-efde752a4c5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:38<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37678,
     "status": "ok",
     "timestamp": 1585114359850,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "jRcIhZcDVmMH",
    "outputId": "0653fd1b-c652-4f29-813e-d8d00657bb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5938 at threshold: 0.820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.491393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.093067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.315875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.520750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.577125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.491393\n",
       "std     0.204939   0.093067\n",
       "min     0.200000   0.315875\n",
       "25%     0.370000   0.413500\n",
       "50%     0.540000   0.520750\n",
       "75%     0.710000   0.577125\n",
       "max     0.880000   0.593750"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1585114364646,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "fBIpTWcaVmMV",
    "outputId": "0647d949-9b5f-4462-b8f5-d530e2c78efb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c7b0788d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIWCAYAAAClXRAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQ3RNIlfVmMZ"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1585111700390,
     "user": {
      "displayName": "加藤裕也",
      "photoUrl": "",
      "userId": "03034409054478693093"
     },
     "user_tz": -540
    },
    "id": "Zkp1_CzwVmMa",
    "outputId": "2ce36c1e-d069-4870-a6ff-d2fe27824f22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1DHg35FVmMf"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDmu3HJ5V8bS"
   },
   "source": [
    "# 追加課題\n",
    "②clean-workflow-in-keras.ipynb の「7  5. Define UNet model for training.」と書かれたセルをコードリーディングしてください。どのようにU-Net構造を実現しているか、夕方の学習共有の時間に説明してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcly5gDobebX"
   },
   "source": [
    "# 当該コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQ7pclw3bcjS"
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                          Conv2DTranspose, Dropout, Input, MaxPooling2D,\n",
    "                          UpSampling2D, concatenate)\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    n = Dropout(do)(n) if do else n\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    return Concatenate()([m, n]) if res else n\n",
    "\n",
    "\n",
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "    if depth > 0:\n",
    "        n = conv_block(m, dim, acti, bn, res)\n",
    "        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "        m = level_block(m, int(inc * dim), depth - 1,\n",
    "                        inc, acti, do, bn, mp, up, res)\n",
    "        if up:\n",
    "            m = UpSampling2D()(m)\n",
    "            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "        else:\n",
    "            m = Conv2DTranspose(dim, 3, strides=2,\n",
    "                                activation=acti, padding='same')(m)\n",
    "        n = Concatenate()([n, m])\n",
    "        m = conv_block(n, dim, acti, bn, res)\n",
    "    else:\n",
    "        m = conv_block(m, dim, acti, bn, res, do)\n",
    "    return m\n",
    "\n",
    "\n",
    "def UNet(params):\n",
    "\n",
    "    img_shape = params['input_dim']\n",
    "    out_ch = 1\n",
    "    start_ch = 8\n",
    "    depth = 3\n",
    "    inc_rate = 2.\n",
    "    activation = 'relu'\n",
    "    dropout = 0.5\n",
    "    batchnorm = False\n",
    "    maxpool = True\n",
    "    upconv = True\n",
    "    residual = False\n",
    "\n",
    "    i = Input(shape=img_shape)\n",
    "    o = level_block(i, start_ch, depth, inc_rate, activation,\n",
    "                    dropout, batchnorm, maxpool, upconv, residual)\n",
    "    o = Conv2D(out_ch, 1)(o)\n",
    "    # Sigmoid activation is used because model is trained with binary_crossentropy.\n",
    "    o =  Activation('sigmoid')(o)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia0PUBjgb2PR"
   },
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03-models_pretrained_and_more.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
