{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# データの前処理\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot-encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_o = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_o = enc.fit_transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape)\n",
    "print(y_train_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_o, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x, w, b):\n",
    "    \"\"\"\n",
    "    パラメータ\n",
    "    ---------------------\n",
    "    x : 入力値\n",
    "\n",
    "    return\n",
    "    ---------------------\n",
    "    a　：　出力\n",
    "    \"\"\"\n",
    "    # filter_size\n",
    "    filter_size = w.shape[0]\n",
    "\n",
    "    # z の要素数 \n",
    "    x_shape = x.shape[0]\n",
    "\n",
    "    # aのから配列\n",
    "    a = np.zeros(x_shape - (filter_size -1))\n",
    "    for i in range(len(a)):\n",
    "        a[i] = (x[i : i + filter_size] @ w) + b\n",
    "    return a.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_based(self, layer):\n",
    "    layer.w -= layer.lr * layer.dw\n",
    "    layer.b -= layerlr * layer.db\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, w, b, da):\n",
    "    \"\"\"\n",
    "    パラメータ\n",
    "    ---------------------\n",
    "    delta_a : 入力値\n",
    "    \n",
    "    return\n",
    "    ---------------------\n",
    "    z　：　出力\n",
    "    \"\"\"    \n",
    "    filter_size = x.shape[0] -1\n",
    "    x_size = x.shape[0]\n",
    "    w_size = w.shape[0]\n",
    "    \n",
    "    # w, bの勾配計算\n",
    "    dw = np.zeros(filter_size)\n",
    "    \n",
    "    for i in range(filter_size):\n",
    "        dw[i] = x[i : i + da.shape[0]] @ da\n",
    "    db = da.sum(axis=0)\n",
    "    \n",
    "    dx = np.zeros(x_size)\n",
    "    for j in range(x_size):\n",
    "        back_filter = 0\n",
    "        for s in range(w_size):\n",
    "            if j-s < 0 or j-s > len(n_out) - 1:\n",
    "                back_filter += 0 * w[s]\n",
    "            else:\n",
    "                back_filter += da[j - s] * w[s]\n",
    "        dx[j] = back_filter   \n",
    "        \n",
    "    return dx, dw, db\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チャンネル数を1に限定した1次元畳み込み層クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    \"\"\"\n",
    "      １次元畳み込み層のクラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x, w, b):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        x : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        a　：　出力\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "        # filter_size\n",
    "        self.filter_size = w.shape[0]\n",
    "        # x の要素数 \n",
    "        self.x_size = x.shape[0]\n",
    "        # wの要素数\n",
    "        self.w_size = w.shape[0]\n",
    "\n",
    "        # aのから配列\n",
    "        self.a = np.zeros(self.x_size - (self.filter_size -1))\n",
    "        for i in range(len(self.a)):\n",
    "            self.a[i] = (self.x[i : i + self.filter_size] @ self.w) + self.b\n",
    "        return self.a.astype(int)\n",
    "    \n",
    "    def backward(self, da):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        delta_a : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        z　：　出力\n",
    "        \"\"\" \n",
    "\n",
    "        # w, bの勾配計算\n",
    "        dw = np.zeros(self.filter_size -1)\n",
    "\n",
    "        for i in range(self.filter_size -1):\n",
    "            dw[i] = self.x[i : i + da.shape[0]] @ da\n",
    "        db = da.sum(axis=0)\n",
    "\n",
    "        dx = np.zeros(self.x_size)\n",
    "        for j in range(len(dx)):\n",
    "            lox = 0\n",
    "            for s in range(self.w_size):\n",
    "                if j-s < 0 or j-s > len(self.a) - 1:\n",
    "                    lox += 0 * self.w[s]\n",
    "                else:\n",
    "                    lox += da[j - s] * self.w[s]\n",
    "            dx[j] = lox  \n",
    "            \n",
    "        return dx, dw, db\n",
    "    \n",
    "    def out_size(n_in, p, f, s):\n",
    "        \"\"\"\n",
    "        n_in :  入力サイズ \n",
    "        p : ある方向へのパディング数\n",
    "        f :  フィルタのサイズ\n",
    "        s : ストライドのサイズ\n",
    "        \"\"\"\n",
    "        out = (n_in + (2*p) - f) / s + 1\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(n_in, p, f, s):\n",
    "    \"\"\"\n",
    "    n_in :  入力サイズ \n",
    "    p : ある方向へのパディング数\n",
    "    f :  フィルタのサイズ\n",
    "    s : ストライドのサイズ\n",
    "    \"\"\"\n",
    "    n_out = (n_in + (2*p) - f) / s + 1\n",
    "    \n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　入力\n",
    "x = np.array([1,2,3,4])\n",
    "# 重み\n",
    "w = np.array([3, 5, 7])\n",
    "# バイアス\n",
    "b = np.array([1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc1 = SimpleConv1d()\n",
    "n_out = sc1.forward(x, w, b)\n",
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バックプロパゲーションの誤差\n",
    "da = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30. 110. 170. 140.]\n",
      "[50. 80.]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "dx, dw, db = sc1.backward(da)\n",
    "print(dx)\n",
    "print(dw)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = np.array([[1,2,3,4],\n",
    "               [2,3,4,5]])\n",
    "\n",
    "\n",
    "w_ = np.array([[[1,1,2],[2,1,1]],\n",
    "              [[2,1,1],[1,1,1]],\n",
    "              [[1,1,1],[1,1,1]]])\n",
    "\n",
    "\n",
    "b_ = np.array([1,2,3])\n",
    "\n",
    "# フォワードの出力\n",
    "out_ = np.array([[21,29],\n",
    "                [18,25],\n",
    "                [18,24]])\n",
    "\n",
    "b_.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4, 5]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.reshape(2, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, w, b):\n",
    "    \"\"\"\n",
    "    パラメータ\n",
    "    ---------------------\n",
    "    x : 入力値\n",
    "    \n",
    "    return\n",
    "    ---------------------\n",
    "    a　：　出力\n",
    "    \"\"\"\n",
    "    #出力チャネル、入力チャネル、filter数\n",
    "    FN, C, FS = w.shape # (出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
    "    C, W = x.shape # (入力チャンネル数、特徴量数)\n",
    "\n",
    "    # 出力するaの空配列を作成\n",
    "    a = np.zeros((FN, (W - (FS - 1)))) # (出力チャンネル数、特徴量数)\n",
    "    # aを計算して出力\n",
    "    for i in range(FN):\n",
    "        index = np.empty((0, FS), int)\n",
    "        for j in range(W - (FS - 1)):\n",
    "            index_to_add = np.arange(j, j+FS)\n",
    "            index = np.append(index, [index_to_add], axis=0)\n",
    "        a[i] = (x[:, index] * w[i]).sum(axis=1).sum(axis=1)\n",
    "    a += b.reshape(-1,1)\n",
    "    return a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 29.],\n",
       "       [18., 25.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out = forward(x_, w_, b_)\n",
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delta_aの値\n",
    "loss_ = np.array([[9,11],\n",
    "                [32,35],\n",
    "                [52,56]])\n",
    "\n",
    "# バックワードの勾配\n",
    "x_delta = np.array([[125,230,204,113],\n",
    "                    [102,206,195,102]])\n",
    "\n",
    "\n",
    "w_delta = np.array([[[31,51,71],[51,71,91]],\n",
    "                    [[102,169,236],[169,236,303]],\n",
    "                    [[164,272,380],[272,380,488]]])\n",
    "loss_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_backward(x_, w_, loss_):\n",
    "    \"\"\"\n",
    "    パラメータ\n",
    "    ---------------------\n",
    "    delta_a : 入力値\n",
    "    \n",
    "    return\n",
    "    ---------------------\n",
    "    z　：　出力\n",
    "    \"\"\"\n",
    "    #１行のx要素数\n",
    "    x_size = x_[0].shape[0]\n",
    "    \n",
    "    x_size2 = x_[0].shape[0] -1\n",
    "    # xのチャネル数\n",
    "    x_cha = x_.shape[0]\n",
    "    # wの要素数\n",
    "    w_size = w_[0].shape[1]\n",
    "    # loss要素数\n",
    "    loss_size = loss_[0].shape[0]\n",
    "    # lossのチャネル数\n",
    "    loss_cha = loss_.shape[0]\n",
    "    #１行のn_out要素数\n",
    "    n_out_size = n_out.shape[1]\n",
    "\n",
    "    # w, bの勾配計算\n",
    "    dw = np.zeros([loss_cha,x_cha, x_size2])\n",
    "    for k in range(loss_cha):\n",
    "        #各チャネル保管\n",
    "        f_2 = np.zeros([loss_size,  x_cha, x_size2])\n",
    "        for j in range(loss_size):\n",
    "            #conv一時保管\n",
    "            f_1 = np.zeros([x_cha, x_size2])\n",
    "            for i in range(x_cha):\n",
    "                f_1[i] = x_[j][i : i + x_size2] * loss_[k][j]\n",
    "            f_2[j] = f_1\n",
    "        dw[k] = np.sum(f_2, axis=0)\n",
    "    \n",
    "    # bの勾配計算\n",
    "    db = loss_.sum(axis=1)\n",
    "    \n",
    "    #デルタxの計算\n",
    "    dx = np.zeros([x_cha, x_size])\n",
    "    b_1 = np.zeros([x_cha, x_size])\n",
    "    b_2 = np.zeros(x_size)\n",
    "    for l in range(loss_cha):\n",
    "        for k in range(x_cha):\n",
    "            for j in range(x_size):\n",
    "                back_filter = 0\n",
    "                for s in range(w_size):\n",
    "                    if j-s < 0 or j-s > n_out_size - 1:\n",
    "                        back_filter += 0 * w_[l][k][s]\n",
    "                    else:\n",
    "                        back_filter += loss_[l][j - s] * w_[l][k][s]\n",
    "                b_2[j] = back_filter\n",
    "            b_1[k] = b_2\n",
    "        dx += b_1\n",
    "        \n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx, dw, db = cv_backward(x_, w_, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125., 230., 204., 113.],\n",
       "       [102., 206., 195., 102.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 31.,  51.,  71.],\n",
       "        [ 51.,  71.,  91.]],\n",
       "\n",
       "       [[102., 169., 236.],\n",
       "        [169., 236., 303.]],\n",
       "\n",
       "       [[164., 272., 380.],\n",
       "        [272., 380., 488.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  67, 108])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャネル数を限定しない１次元畳み込み層のクラス\n",
    "    ----------------------------\n",
    "    parameter\n",
    "    ----------------------------\n",
    "    FN: 出力チャネル\n",
    "    FC：入力チャネル\n",
    "    FS：　フィルター要素数\n",
    "    \"\"\"\n",
    "    def __init__(self, FN, C, FS, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        self.w = self.sigma * np.random.randn(FN, C, FS)\n",
    "        self.b = np.zeros((FN, 1))\n",
    "        self.h_w = self.sigma * np.random.randn(FN, C, FS)\n",
    "        self.h_b = np.zeros((FN, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        x : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        a　：　出力\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        #出力チャネル、入力チャネル、filter数\n",
    "        FN, FC,FS  = self.w.shape\n",
    "        C, W = self.x.shape\n",
    "\n",
    "        # 出力するaの空配列を作成\n",
    "        self.n_out = np.zeros((FN, (W - (FS - 1)))) # (出力チャンネル数、特徴量数)\n",
    "        # aを計算して出力\n",
    "        for i in range(FN):\n",
    "            index = np.empty((0, FS), int)\n",
    "            for j in range(W - (FS - 1)):\n",
    "                index_to_add = np.arange(j, j+FS)\n",
    "                index = np.append(index, [index_to_add], axis=0)\n",
    "            self.n_out[i] = (x[:, index] * self.w[i]).sum(axis=1).sum(axis=1)\n",
    "        self.n_out += self.b.reshape(-1,1)\n",
    "        return self.n_out  \n",
    "    \n",
    "    def backward(self, loss):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        delta_a : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        z　：　出力\n",
    "        \"\"\"\n",
    "        #出力チャネル、入力チャネル、filter数\n",
    "        FN, FC,FS  = self.w.shape\n",
    "        C, W = self.x.shape\n",
    "        LC, LS = loss.shape \n",
    "        print(self.n_out.shape)\n",
    "        n_out_size = self.n_out.shape[1]\n",
    "        #１行のx要素数\n",
    "        self.dw = np.zeros(self.w.shape)\n",
    "        \n",
    "           # w, bの勾配計算\n",
    "        dw = np.zeros([FN, FC, FS])\n",
    "        for k in range(LC):\n",
    "            #各チャネル保管\n",
    "            f_2 = np.zeros([FN, FC, FS])\n",
    "            for j in range(LS):\n",
    "                #conv一時保管\n",
    "                f_1 = np.zeros([C, FS])\n",
    "                for i in range(C):\n",
    "                    for s in range(W - (FS-1)):\n",
    "                        f_1[i] = self.x[i][s : s + FS] * loss_[k][j]\n",
    "                f_2[j] = f_1\n",
    "            dw[k] = np.sum(f_2, axis=0)\n",
    "\n",
    "        # bの勾配計算\n",
    "        self.db = loss_.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "        #デルタxの計算\n",
    "        #デルタxの計算\n",
    "        dx = np.zeros([C, W])\n",
    "        b_1 = np.zeros([C, W])\n",
    "        b_2 = np.zeros(W)\n",
    "        for l in range(LC):\n",
    "            for k in range(C):\n",
    "                for j in range(W):\n",
    "                    back_filter = 0\n",
    "                    for s in range(FS):\n",
    "                        if j-s < 0 or j-s > n_out_size - 1:\n",
    "                            back_filter += 0 * self.w[l][k][s]\n",
    "                        else:\n",
    "                            back_filter += loss[l][j - s] * self.w[l][k][s]\n",
    "                    b_2[j] = back_filter\n",
    "                b_1[k] = b_2\n",
    "            dx += b_1\n",
    "            self = self.update_based(self)\n",
    "            return dx\n",
    "    \n",
    "    def update_based(self, layer):\n",
    "        layer.w -= 0.001 * layer.dw\n",
    "        layer.b -= 0.001 * layer.db\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV1 = Conv1d(FN=3,  C=2, FS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08589167,  0.11366768],\n",
       "       [-0.07352675, -0.09218305],\n",
       "       [ 0.01574792,  0.02128156]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV1.forward(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01268228,  0.07519487,  0.03841887, -0.08852691],\n",
       "       [ 0.03331255,  0.13008874,  0.23095026,  0.14876413]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV1.backward(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.w = initializer.W( self.n_nodes1, self.n_nodes2)\n",
    "        self.b =  initializer.B(self.n_nodes2)\n",
    "        # adagrad用\n",
    "        #if Adagrad = True: \n",
    "        self.h_w = np.zeros((n_nodes1, n_nodes2))\n",
    "        self.h_b = np.zeros(n_nodes2)\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"   \n",
    "        # 前層が畳み込み層の場合、出力チャンネル数に該当する次元を減らす\n",
    "        if len(X.shape) > 2:\n",
    "            self.X_shape = X.shape # backward時の復元用にshapeは保存しておく\n",
    "            X = X.reshape(X.shape[1], X.shape[0] * X.shape[2])\n",
    "        self.X = X\n",
    "        \n",
    "        self.A =  np.dot(X, self.w) + self.b\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.db = np.sum(dA, axis=0)\n",
    "#         print(self.X.shape)\n",
    "#         print(dA.shape)\n",
    "        self.dw = np.dot(self.X.T, dA)\n",
    "#         print(dA.shape)\n",
    "#         print(self.w.T.shape)\n",
    "        dZ = np.dot(dA, self.w.T)\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def forward(self, A):\n",
    "        # overflow対策\n",
    "        A_max = np.max(A, axis=1)\n",
    "        exp_A = np.exp(A - A_max.reshape(-1, 1))\n",
    "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
    "        return exp_A / sum_exp_A\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        loss = self._cross_entropy(Z, Y)\n",
    "        D  = Z - Y\n",
    "        return D, loss \n",
    "    \n",
    "    def _cross_entropy(self,Z, y):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ーーーーーーーーーーーーー\n",
    "        y : 正解ラベル（one-hot表現）\n",
    "        z３　：　クラスの確率\n",
    "        n : バッチサイズ\n",
    "\n",
    "        \"\"\"\n",
    "        if y.ndim == 1:    # 次元が 1 の場合\n",
    "            y = y.reshape(1, y.size)\n",
    "        batch_size = y.shape[0]\n",
    "        return -1* np.sum(y * np.log(Z)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def forward(self, A):\n",
    "        self.mask = (A <= 0)\n",
    "        a = A.copy()\n",
    "        self.A = A\n",
    "        a[self.mask] = 0\n",
    "        return np.maximum(0, A)\n",
    "      \n",
    "    def backward(self, dA):\n",
    "        #dA[self.mask] = 0\n",
    "        out =  np.where(self.A > 0., 1., 0.)\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer():\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = 1/ np.sqrt(sigma)\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :　重みの初期値\n",
    "        \"\"\"\n",
    "        self.w = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return self.w\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :　バイアスの初期値\n",
    "        \"\"\"\n",
    "        self.b = self.sigma * np.random.randn(n_nodes2)\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = np.sqrt(2 / sigma)\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :　重みの初期値\n",
    "        \"\"\"\n",
    "        self.w = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return self.w\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :　バイアスの初期値\n",
    "        \"\"\"\n",
    "        self.b = self.sigma * np.random.randn(n_nodes2)\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, batch):\n",
    "        self.lr = lr\n",
    "        self.batch = batch\n",
    "        # 過去の勾配の２乗和の保管用\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        layer.h_w += (layer.dw/ self.batch) * (layer.dw/ self.batch)\n",
    "        layer.h_b += (layer.db/self.batch) * (layer.db / self.batch)\n",
    "        layer.w -= self.lr * (1 / (np.sqrt(layer.h_w) + 1e-07)) * (layer.dw/ self.batch)\n",
    "        layer.b -= self.lr * (1 / (np.sqrt(layer.h_b) + 1e-07)) * (layer.db/ self.batch)\n",
    "        \n",
    "#         layer.h_W += layer.dW * layer.dW\n",
    "#         layer.h_B += layer.dB * layer.dB\n",
    "#         layer.W -= self.lr * (1 / (np.sqrt(layer.h_W) + 1e-07)) * layer.dW\n",
    "#         layer.B -= self.lr * (1 / (np.sqrt(layer.h_B) + 1e-07)) * layer.dB\n",
    "\n",
    "        return layer\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=10):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャネル数を限定しない１次元畳み込み層のクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, FN, FC, FS, sigma, optimizer):\n",
    "        self.filter_size = FS\n",
    "        self.optimizer = optimizer\n",
    "        #Heの場合のシグマ\n",
    "        self.sigma = np.sqrt(2 / sigma)\n",
    "        # 初期化\n",
    "        self.w = self.sigma * np.random.randn(FN, FC, FS)\n",
    "        self.b = np.zeros((FN, 1))\n",
    "        #更新用\n",
    "        self.h_w = np.zeros((FN, FC, FS))\n",
    "        self.h_b = ((FN, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        x : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        a　：　出力\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        #出力チャネル、入力チャネル、filter数\n",
    "        FN, FC,FS  = self.w.shape\n",
    "        N, C, W = self.x.shape\n",
    "\n",
    "        # 出力するaの空配列を作成\n",
    "        self.n_out = np.zeros((N, FN, (W - (FS - 1)))) # (出力チャンネル数、特徴量数)\n",
    "    \n",
    "        # aを計算して出力\n",
    "        for n in range(N):\n",
    "            for i in range(FN):\n",
    "                index = np.empty((0, FS), int)\n",
    "                for j in range(W - (FS - 1)):\n",
    "                    index_to_add = np.arange(j, j+FS)\n",
    "                    index = np.append(index, [index_to_add], axis=0)\n",
    "                self.n_out[n][i] = (x[n, :, index] * self.w[i]).sum(axis=1).sum(axis=1)\n",
    "            self.n_out[n] += self.b\n",
    "        return self.n_out  \n",
    "    \n",
    "    def backward(self, loss):\n",
    "        \"\"\"\n",
    "        パラメータ\n",
    "        ---------------------\n",
    "        delta_a : 入力値\n",
    "\n",
    "        return\n",
    "        ---------------------\n",
    "        z　：　出力\n",
    "        \"\"\"\n",
    "        #出力チャネル、入力チャネル、filter数\n",
    "        FN, FC,FS  = self.w.shape\n",
    "        N, C, W = self.x.shape\n",
    "        LC, LS, _ = loss.shape \n",
    "        n_out_size = self.n_out.shape[1]\n",
    "        # wの勾配\n",
    "#         self.dw = np.zeros([FN, FC, FS])\n",
    "#         for c in range(C):\n",
    "#             for fn in range(FN):\n",
    "#                 for fc in range(FC):\n",
    "#                     for fs in range(FS):\n",
    "#                         for j in range(W-(FS-1)):\n",
    "#                             self.dw[fn, fc, fs] += loss[c, fn, j]* self.x[fn, fc, j + fs]\n",
    "        self.dw = np.zeros(self.w.shape)\n",
    "        for n in range(N):\n",
    "            for i in range(FS):\n",
    "                for j in range(W - (FS - 1)):\n",
    "                    self.dw[:, :, i] += loss[n, :, j][:, np.newaxis] * self.x[n, :, i+j][np.newaxis, :]\n",
    "\n",
    "        # bの勾配計算\n",
    "        self.db = loss.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "        #デルタxの計算\n",
    "        #デルタxの計算\n",
    "        dx = np.zeros([C, W])\n",
    "        b_1 = np.zeros([C, W])\n",
    "        b_2 = np.zeros(W)\n",
    "        for l in range(LC):\n",
    "            for k in range(C):\n",
    "                for j in range(W):\n",
    "                    back_filter = 0\n",
    "                    for s in range(FS):\n",
    "                        if j-s < 0 or j-s > n_out_size - 1:\n",
    "                            back_filter += 0 * self.w[l][k][s]\n",
    "                        else:\n",
    "                            back_filter += loss[l][j - s] * self.w[l][k][s]\n",
    "                    b_2[j] = back_filter\n",
    "                b_1[k] = b_2\n",
    "            dx += b_1\n",
    "            self = self.update_based(self)\n",
    "            return dx\n",
    "    \n",
    "    def update_based(self, layer):\n",
    "        layer.w -= 0.001 * layer.dw\n",
    "        layer.b -= 0.001 * layer.db\n",
    "        return layer\n",
    "#         # 更新\n",
    "#         self = self.optimizer.update(self)\n",
    "#         return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \n",
    "    def __init__(self, lr=0.01,sigma=0.1, n_iter=1, batch=3, FN=3, C=1, FS=784, vervose=False):\n",
    "        self.iter = n_iter\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.batch = batch\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        self.FN = FN\n",
    "        self.C = C\n",
    "        self.FS = FS\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y,  X_val=None, y_val=None):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 =  200\n",
    "        self.n_output = 10\n",
    "    \n",
    "        \n",
    "        #更新方法の定義\n",
    "        self.optimizer = AdaGrad(self.lr, self.batch)\n",
    "        #　畳み込み層の定義\n",
    "        self.Conv1d = Conv1d(self.FN, self.C, self.FS, self.sigma, self.optimizer)\n",
    "        self.conv_activation = Relu()\n",
    "        # 全結合層の定義\n",
    "        self.FC3 = FC(self.FN, self.n_output, HeInitializer(self.FN), self.optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        # 学習開始\n",
    "        for i in range(self.iter):\n",
    "            # １エポックのloss記録保管\n",
    "            history = np.zeros(X.shape[0] // self.batch)\n",
    "            val_history = np.zeros(X_val.shape[0] // self.batch)\n",
    "            #  バッチサイズのカウント\n",
    "            count = 0\n",
    "            #　ミニバッチの取り出しコード\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # forward\n",
    "                A0 = self.Conv1d.forward(mini_X_train)\n",
    "                Z0 = self.conv_activation.forward(A0)\n",
    "                A1 = self.FC3.forward(Z0)\n",
    "                Z1 = self.activation3.forward(A1)\n",
    "\n",
    "                # backward\n",
    "                dA1, history[count] = self.activation3.backward(Z1, mini_y_train)\n",
    "                dZ1 = self.FC3.backward(dA1)\n",
    "                dA0 = self.conv_activation.backward(dZ1)\n",
    "                dZ0 = self.Conv1d.backward(dA0)\n",
    "                count += 1\n",
    "                \n",
    "            A0 = self.Conv1d.forward(X)\n",
    "            Z0 = self.conv_activation.forward(A0)\n",
    "            A1 = self.FC3.forward(Z0)\n",
    "            Z1= self.activation3.forward(A1)\n",
    "            \n",
    "            _, history= self.activation3.backward(Z1, y)\n",
    "            self.loss[i] = history\n",
    "            \n",
    "            # X_valあった場合の処理\n",
    "            if np.any(X_val): \n",
    "                A0 = self.Conv1d.forward(X_val)\n",
    "                Z0 = self.conv_activation.forward(A0)\n",
    "                A1 = self.FC3.forward(Z0)\n",
    "                Z1 = self.activation3.forward(A1)\n",
    "                # 学習記録\n",
    "                _, val_history = self.activation3.backward(Z1, y_val)\n",
    "                self.val_loss[i] = val_history\n",
    "            \n",
    "            \n",
    "    # 推定\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A0 = self.Conv1d.forward(X)\n",
    "        Z0 = self.conv_activation(A0)\n",
    "        A1 = self.FC3.forward(Z0)\n",
    "        Z1 = self.activation3.forward(A1)\n",
    "        return np.argmax(Z1, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# データの前処理\n",
    "X_train = X_train.reshape(-1, 1, 784)\n",
    "X_test = X_test.reshape(-1, 1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:,  np.newaxis])\n",
    "#訓練データから更に検証データを生成\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "SDNNC = ScratchDeepNeuralNetrowkClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-307f325aec99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSDNNC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-158-f8d29dd8fc80>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdA0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdZ0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-5560806ba279>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_out_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                             \u001b[0mback_filter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                             \u001b[0mback_filter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SDNNC.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SDNNC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-925e78cd46ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "処理が重く回しきれなかったので中断しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
